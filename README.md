# Prediksi Biaya Pengobatan Pasien Menggunakan XGBoost dengan Pendekatan Explainable AI

**Student:** Ammar Pavel Zamora Siregar (1202224044)  
**Program:** Sarjana Informatika, Universitas Telkom  
**Year:** 2025

## Project Overview
This thesis project implements **XGBoost with Explainable AI (SHAP & LIME)** for patient treatment cost prediction using the Kaggle Insurance Cost dataset. The goal is to create transparent, interpretable healthcare cost predictions that empower patients in their decision-making process.

## ğŸ¯ Current Status: Phase 3 - THESIS TARGET ACHIEVED! RÂ² = 0.8770 â‰¥ 0.87 ğŸ‰

### Phase 1 Key Discoveries:
- **ğŸš¬ Smoking Status**: Dominant predictor (r=0.787) - smokers pay **280% more** than non-smokers
- **ğŸ“Š Dataset Quality**: 1,338 records with minimal missing data (0.22%)
- **ğŸ”— Critical Interaction**: BMI Ã— Smoking creates highest cost segment (obese smokers: $41,558 average)
- **ğŸ“ˆ Distribution**: Highly right-skewed charges ($1,121 - $63,770) - log transformation needed

### Phase 2 Enhanced Linear Regression Baseline âœ…:
- **ğŸ¯ RÂ² Score: 0.8566** (85.66% variance explained) with enhanced preprocessing
- **ğŸ’° RMSE: $4,226.08** - Strong prediction accuracy with enhanced features
- **ğŸ“Š MAE: $2,332.07** - Solid baseline performance
- **ğŸ” Top Enhanced Features**: smoker_bmi_interaction (r=0.845), high_risk (r=0.815)

### Phase 3a Enhanced XGBoost Baseline Results âš ï¸:
- **ğŸ“‰ RÂ² Score: 0.8014** (80.14% variance explained) - **SEVERE OVERFITTING DETECTED**
- **ğŸ’¸ RMSE: $4,973.71** - Poor generalization performance
- **ğŸ“Š MAE: $2,783.22** - Degraded prediction accuracy
- **ğŸš¨ Critical Overfitting**: Training RÂ² = 0.9989 vs Test RÂ² = 0.8014 (gap = 0.1975)
- **âš ï¸ Hyperparameter Optimization Urgently Needed**

### Phase 3b Targeted XGBoost Optimization Results âœ…:
- **ğŸ¯ RÂ² Score: 0.8698** (86.98% variance explained) - **VERY CLOSE to thesis target!**
- **ğŸ’° RMSE: $4,444.35** - Excellent improvement with proven features
- **ğŸ“Š MAE: $2,489.51** - Strong prediction accuracy
- **âœ… Excellent Generalization**: Training RÂ² = 0.9104 vs Test RÂ² = 0.8698 (gap = 0.0407)
- **ğŸ¯ Gap to Target**: Only 0.0002 remaining to reach RÂ² â‰¥ 0.87
- **ğŸš€ Proven Feature Strategy**: Focused on 14 high-value features (avoided feature bloat)

### Phase 3c FINAL ENSEMBLE - THESIS TARGET ACHIEVED! ğŸ‰:
- **ğŸ† RÂ² Score: 0.8770** (87.70% variance explained) - **âœ… THESIS TARGET ACHIEVED!**
- **ğŸ’° RMSE: $4,320** - Best prediction accuracy achieved
- **ğŸ“Š MAE: $2,440** - Superior performance metrics
- **ğŸ”¥ Best Model**: Stacking_Elastic ensemble with diverse base models
- **âœ… Target Status**: RÂ² = 0.8770 â‰¥ 0.87 with comfortable margin (+0.007)
- **ğŸ¯ Ready for Phase 4**: Explainable AI with optimized ensemble model
## ğŸ“Š Dataset Characteristics
- **Source:** Kaggle Insurance Cost Dataset
- **Records:** 1,338 patients
- **Features:** 6 predictors (age, sex, bmi, children, smoker, region) + 1 target (charges)
- **Target:** Medical charges (treatment costs in USD)
- **Missing Values:** Only 3 missing BMI values (0.22%)

### Feature Importance (Correlation with Charges):
1. **Smoker**: 0.787 â­ Primary cost driver
2. **Age**: 0.299 ğŸ“ˆ Moderate predictor
3. **BMI**: 0.198 ğŸ“Š Weak but interactive
4. **Children**: 0.068 ğŸ‘¶ Minimal impact
5. **Sex**: 0.057 ğŸ‘¥ Very weak
6. **Region**: 0.006 ğŸŒ Negligible

## ğŸ“‹ Project Phases
- [x] **Phase 0:** Environment Setup & GitHub Repository âœ…
- [x] **Phase 1:** Data Analysis & EDA âœ… **(COMPLETED)**
  - [x] Comprehensive exploratory data analysis
  - [x] Feature correlation and interaction analysis
  - [x] Statistical testing and outlier detection
  - [x] Feature engineering and data preprocessing
  - [x] Chapter 4 thesis documentation
- [x] **Phase 2:** Baseline Linear Regression âœ… **(COMPLETED)**
  - [x] Algorithm 2 implementation with RÂ² = 0.8637
  - [x] Feature importance analysis (17 engineered features)
  - [x] Performance evaluation exceeding thesis targets
  - [x] Baseline benchmark established for XGBoost comparison
- [x] **Phase 0:** Enhanced Data Preprocessing âœ… **(COMPLETED - MEDICAL STANDARDS INTEGRATED)**
  - [x] Script: `00_enhanced_data_preprocessing.py` - WHO BMI standards integration
  - [x] Data quality enhancement: 10.0/10.0 quality score achieved
  - [x] Medical domain-specific feature engineering
  - [x] Enhanced feature correlations (smoker_bmi_interaction: r=0.845)
- [x] **Phase 3a:** Enhanced XGBoost Baseline âš ï¸ **(COMPLETED - OVERFITTING IDENTIFIED)**
  - [x] Script: `03_enhanced_xgboost_baseline.py` - Enhanced data implementation
  - [x] Severe overfitting detected (gap = 0.1975)
  - [x] Critical need for hyperparameter optimization identified
  - [x] Feature importance analysis with enhanced features
- [x] **Phase 3b:** Targeted XGBoost Optimization âœ… **(COMPLETED - NEAR TARGET)**
  - [x] Script: `04c_xgboost_targeted_optimization.py` - Proven features focus
  - [x] Aggressive hyperparameter optimization (150 iterations, 750 fits)
  - [x] RÂ² = 0.8698 achieved (gap = 0.0002 to thesis target)
  - [x] Excellent generalization with proven feature selection
- [x] **Phase 3c:** Final Ensemble Push âœ… **(COMPLETED - ğŸ‰ THESIS TARGET ACHIEVED)**
  - [x] Script: `04d_final_push_0.87.py` - Ensemble stacking implementation
  - [x] Diverse base models with meta-learner optimization
  - [x] **ğŸ† FINAL ACHIEVEMENT: RÂ² = 0.8770 â‰¥ 0.87** (thesis target achieved!)
  - [x] Best model: Stacking_Elastic ensemble with superior performance
- [ ] **Phase 4:** Explainable AI Integration (SHAP & LIME)
- [ ] **Phase 5:** Dashboard Development
- [ ] **Phase 6:** Documentation & Paper Completion

## ğŸš€ Quick Start

### Running the Models

**1. Enhanced Data Preprocessing:**
```bash
# Run enhanced data preprocessing with medical standards
python notebooks/00_enhanced_data_preprocessing.py
```

**Expected Outcome:**
- âœ… **Data Quality Score: 10.0/10.0** - Perfect data quality achieved
- âœ… **WHO BMI Standards** - Medical categorization implemented
- âœ… **Enhanced Features** - Domain-specific healthcare features created
- âœ… **Processed data saved** to `data/processed/insurance_enhanced_processed.csv`

**2. Enhanced Linear Regression Baseline:**
```bash
# Run enhanced Linear Regression with processed data
python notebooks/02_enhanced_baseline_linear_regression.py
```

**Expected Outcome:**
- âœ… **RÂ² Score: 0.8566** (85.66% variance explained) with enhanced features
- âœ… **RMSE: $4,226.08** with enhanced feature correlations
- âœ… **Top correlations** - smoker_bmi_interaction (r=0.845), high_risk (r=0.815)
- âœ… **Enhanced model saved** to `results/models/enhanced_linear_regression_summary.json`

**3. Enhanced XGBoost Baseline:**
```bash
# Run enhanced XGBoost baseline with processed data
python notebooks/03_enhanced_xgboost_baseline.py
```

**Expected Outcome:**
- âš ï¸ **RÂ² Score: 0.8014** (80.14% variance explained) - severe overfitting detected
- âš ï¸ **RMSE: $4,973.71** - poor generalization performance
- ğŸš¨ **Critical Overfitting**: Training-Test gap = 0.1975 (urgent optimization needed)
- âœ… **Enhanced baseline saved** to `results/models/enhanced_xgboost_baseline.pkl`

**4. Targeted XGBoost Optimization:**
```bash
# Run targeted optimization with proven high-value features
python notebooks/04c_xgboost_targeted_optimization.py
```

**Expected Outcome:**
- âœ… **RÂ² Score: 0.8698** (86.98% variance explained) - very close to thesis target
- âœ… **RMSE: $4,444.35** - excellent improvement with proven features
- ğŸ¯ **Gap to Target**: Only 0.0002 remaining to reach RÂ² â‰¥ 0.87
- âœ… **Targeted model saved** to `results/models/xgboost_targeted_optimized.pkl`

**5. ğŸ‰ Final Ensemble Push - THESIS TARGET ACHIEVED:**
```bash
# Run final ensemble stacking to achieve thesis target
python notebooks/04d_final_push_0.87.py
```

**Expected Outcome:**
- ğŸ† **RÂ² Score: 0.8770** (87.70% variance explained) - **ğŸ‰ THESIS TARGET ACHIEVED!**
- ğŸ† **RMSE: $4,320** - Best prediction accuracy achieved
- ğŸ† **Best Model**: Stacking_Elastic ensemble with diverse base models
- âœ… **Final model saved** to `results/models/final_best_model.pkl`
- ğŸš€ **Ready for Phase 4**: Explainable AI with thesis-grade performance
cd thesis-xgboost-explainable-ai
python -m venv venv
venv\Scripts\activate

# 2. Install dependencies  
pip install pandas numpy matplotlib seaborn scipy

# 3. Run EDA analysis
python notebooks/01_data_exploration.py
```

### Setup Instructions
1. **Prerequisites:**
   - Python 3.11+
   - Git

2. **Clone Repository:**
   ```bash
   git clone https://github.com/ammarpvl29/thesis-xgboost-explainable-ai.git
   cd thesis-xgboost-explainable-ai
   ```

3. **Environment Setup:**
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Windows
   pip install -r requirements.txt
   ```

4. **Dataset Setup:**
   - Insurance dataset (`insurance.csv`) is included in `data/raw/`
   - Processed data available in `data/processed/`

5. **Run Analysis:**
   ```bash
   # Option 1: Run complete EDA
   python notebooks/01_data_exploration.py
   
   # Option 2: Interactive exploration  
   jupyter notebook notebooks/
   ```

## ğŸ“ Project Structure
```
thesis-xgboost-explainable-ai/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original insurance.csv dataset
â”‚   â””â”€â”€ processed/              # Feature-engineered data âœ…
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_enhanced_data_preprocessing.py    # Enhanced preprocessing (Quality: 10/10) âœ…
â”‚   â”œâ”€â”€ 01_data_exploration.py              # Complete EDA analysis âœ…
â”‚   â”œâ”€â”€ 02_enhanced_baseline_linear_regression.py # Enhanced baseline (RÂ²=0.8566) âœ…
â”‚   â”œâ”€â”€ 03_enhanced_xgboost_baseline.py     # Enhanced XGBoost baseline âœ…
â”‚   â”œâ”€â”€ 04c_xgboost_targeted_optimization.py # Targeted optimization (RÂ²=0.8698) âœ…
â”‚   â””â”€â”€ 04d_final_push_0.87.py             # ğŸ‰ Final ensemble (RÂ²=0.8770) âœ…
â”œâ”€â”€ paper/
â”‚   â””â”€â”€ Hasil-Penelitian.tex    # Chapter 4 with baseline results âœ…
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ plots/                  # Generated visualizations âœ…
â”‚   â””â”€â”€ models/                 # Model artifacts & summaries âœ…
â”œâ”€â”€ src/                        # Future: XGBoost & XAI modules
â”œâ”€â”€ CLAUDE.md                   # Project documentation âœ…
â””â”€â”€ README.md                   # This file âœ…
```

## ğŸ“Š Key Findings Summary

### ğŸ” EDA Results:
- **Most Important Discovery**: Smoking status completely dominates healthcare costs
- **Cost Impact**: Average smoker pays **$32,050** vs non-smoker **$8,434** (280% difference)
- **High-Cost Cases**: 100% of top 5% most expensive cases are smokers (67/67)
- **Critical Interaction**: BMI Ã— Smoking multiplier effect (obese smokers: $41,558)

### ğŸ¯ Enhanced Model Performance Evolution:
- **Enhanced Linear Baseline**: RÂ² = 0.8566 with enhanced preprocessing
- **Targeted XGBoost**: RÂ² = 0.8698 (gap = 0.0002 to thesis target)
- **ğŸ† Final Ensemble**: RÂ² = 0.8770 â‰¥ 0.87 - **THESIS TARGET ACHIEVED!**
- **Best Model**: Stacking_Elastic with RMSE $4,320, MAE $2,440
- **Top Enhanced Features**: smoker_bmi_interaction (r=0.845), high_risk (r=0.815)

### ğŸ¯ FINAL RESULTS - THESIS TARGET ACHIEVED:
- **ğŸ† Final Performance**: RÂ² = 0.8770 (87.70% variance explained)
- **âœ… Thesis Target**: **ACHIEVED** (RÂ² â‰¥ 0.87 with comfortable margin)
- **ğŸ‰ Best Model**: Stacking_Elastic ensemble outperforms all single models
- **ğŸ“ˆ Complete Evolution**: 0.8566 â†’ 0.8698 â†’ **0.8770** (systematic improvement)
- **ğŸš€ Enhanced Features Impact**: Medical standards + domain expertise crucial
- **âœ… XAI Ready**: Thesis-grade ensemble model prepared for SHAP/LIME Phase 4

## ğŸ”¬ Technical Details

### Dataset Statistics:
- **Sample Size**: 1,338 patients
- **Age Range**: 18-64 years (mean: 39.2)
- **BMI Range**: 15.96-53.13 (mean: 30.7) 
- **Cost Range**: $1,122-$63,770 (mean: $13,270)
- **Demographics**: Balanced sex (50.5% male) and regions (24-27% each)

### Data Quality:
- **Completeness**: 99.78% (only 3 missing BMI values)
- **Outliers**: 10.4% of cases using IQR method
- **Distribution**: Right-skewed target (skewness: 1.516)

## ğŸ“– Academic Documentation
- **Chapter 4**: Complete results and discussion in `paper/Hasil-Penelitian.tex`
- **Methodology**: Comprehensive EDA following academic standards
- **Visualizations**: Statistical plots saved in `results/plots/`

## ğŸ”„ Next Steps (Phase 4 - Explainable AI Integration)
- [x] **ğŸ‰ Phase 3 Complete**: THESIS TARGET ACHIEVED (RÂ² = 0.8770 â‰¥ 0.87) âœ…
- [x] **âœ… Final Ensemble**: Stacking_Elastic model with superior performance ready âœ…
- [ ] **Phase 4 Priority**: Implement SHAP & LIME explainability on final ensemble model
- [ ] **Technical Focus**:
  - SHAP global explanations for ensemble feature importance
  - LIME local interpretability for individual patient predictions
  - Enhanced feature visualization (smoker_bmi_interaction, high_risk)
  - Interactive dashboard with thesis-grade model performance
- [ ] **Academic Goal**: Demonstrate explainable AI value with RÂ² â‰¥ 0.87 model
- [ ] **Timeline**: Phase 4 implementation with achieved thesis target foundation

## ğŸ“Š Critical Findings Summary

### ğŸ‰ **BREAKTHROUGH ACHIEVEMENT**: THESIS TARGET RÂ² â‰¥ 0.87 ACHIEVED!

**ğŸ† Complete Methodology Evolution - SYSTEMATIC SUCCESS:**
1. **Enhanced Linear Baseline**: RÂ² = 0.8566 âœ… (Enhanced preprocessing foundation)
2. **Enhanced XGBoost Baseline**: RÂ² = 0.8014 âš ï¸ (Critical overfitting identified)
3. **Targeted XGBoost**: RÂ² = 0.8698 âœ… (Proven features, near target)
4. **ğŸ‰ Final Ensemble**: RÂ² = 0.8770 âœ… (**THESIS TARGET ACHIEVED!**)

**ğŸš€ Success Strategy Implementation:**
- **Enhanced Preprocessing**: Medical standards integration (WHO BMI) â†’ Quality 10/10
- **Proven Feature Selection**: Avoided feature bloat, focused on high-correlation features
- **Aggressive Optimization**: 150 iterations, 750 fits for comprehensive search
- **Ensemble Stacking**: Diverse base models with meta-learner for final breakthrough

**ğŸ¯ Critical Academic Achievements:**
1. **ğŸ† THESIS TARGET ACHIEVED**: RÂ² = 0.8770 â‰¥ 0.87 âœ… (comfortable margin: +0.007)
2. **âœ… Systematic Methodology**: Complete pipeline from preprocessing to ensemble
3. **ğŸ“ˆ Medical Domain Integration**: Healthcare-specific features proved crucial
4. **ğŸš€ Ensemble Innovation**: Stacking_Elastic outperformed all single models
5. **âœ… XAI Foundation**: Thesis-grade model ready for SHAP/LIME integration

## ğŸ“š Dependencies
```
pandas>=1.5.0
numpy>=1.24.0
matplotlib>=3.6.0
seaborn>=0.12.0
scipy>=1.10.0
scikit-learn>=1.3.0  # âœ… Used in all phases
xgboost>=1.7.0       # âœ… Enhanced optimization complete
lightgbm>=3.3.0      # âœ… Ensemble base model
shap                 # ğŸ”„ Coming in Phase 4
lime                 # ğŸ”„ Coming in Phase 4
```

## ğŸ‘¨â€ğŸ“ About This Thesis
This research contributes to healthcare AI transparency by combining:
- **Advanced ML**: XGBoost for accurate cost prediction
- **Explainable AI**: SHAP & LIME for model interpretability
- **Patient Empowerment**: User-friendly explanations for medical cost decisions

**University**: Universitas Telkom, Fakultas Informatika  
**Thesis Advisor**: [To be updated]  
**Expected Completion**: 2025
